{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A00240 - SAS Certification Prep Guide Statistical Business Analysis Using SAS 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANOVA Post Hoc Tests** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparisonwise error rate, or the CER.\n",
    "* is the probability of a Type 1 error on a single pairwise test.\n",
    "\n",
    "\n",
    "The experimentwise error rate, or EER, \n",
    "* is the probability of making at least one Type 1 error when you perform the entire set of comparisons. \n",
    "\n",
    "\n",
    "The Tukey method, or honest significant difference test, \n",
    "* conducts all possible pairwise comparisons and controls the EER (experimentwise error rate) to equal the alpha level that you specify. \n",
    "\n",
    "Dunnett's method \n",
    "* is a specialized multiple comparison test that enables you to compare a single control group, such as a placebo in a drug trial, to all other groups or treatments. \n",
    "\n",
    "Diffograms\n",
    "* You can use diffograms to visually assess whether pairs of group means are statistically different.\n",
    "\n",
    "\n",
    "Control Plots\n",
    "* A control plot displays the least squares mean and decision limits. They compare each treatment group to the control group using Dunnett's method.\n",
    "\n",
    "A statistically conservative multiple comparison what test tends to do?\n",
    "* find fewer significant differences than might otherwise be found without adjustment\n",
    "\n",
    "Compared to a multiple comparisons test that controls the experimentwise error rate, what characteristics will a multiple comparisons test that only controls the comparisonwise error rate tend to have?\n",
    "* a higher Type I error rate, but a lower Type II error rate and more significant differences than might otherwise be found\n",
    "\n",
    "\n",
    "Pearson correlation \n",
    "* coefficient as our correlation statistic. The correlation coefficient ranges from -1 to +1. A Pearson correlation coefficient is a measure of linear association.\n",
    "\n",
    "effect of large sample sizes. \n",
    "* As with many statistics, very large sample sizes can result in small p-values.\n",
    "\n",
    "unbalanced data, \n",
    "* data with different sample sizes for the groups.\n",
    "\n",
    "\n",
    "Adjusted R square \n",
    "* is like R-square, but it considers the number of terms in the model in addition to model fit.\n",
    "\n",
    "k-fold cross validation\n",
    "* train and assess the model on k total different partitions of the data for the same model. The results from each holdout set can then be averaged to interpret how well the model generalizes to new data. \n",
    "\n",
    "bootstrapping \n",
    "* is a resampling method that tries to approximate the distribution of the parameter estimates in order to obtain correct standard errors and p-values.\n",
    "\n",
    "the chi-square test\n",
    "* To be certain that the variables are associated. It measures the difference between the observed cell counts and the cell counts that are expected if there's no association between the variables, and the null hypothesis is in fact true.\n",
    "\n",
    "Cramer's V statistic\n",
    "* To measure the magnitude of an association. is one measure of the strength of an association between two categorical variables, and its value is derived from the chi-square statistic. For two-by-two tables, Cramer's V is in the range of -1 to 1, and for larger tables, its in the range of 0 to 1.Values farther away from 0 indicate a relatively strong association between the variables. The closer Cramer's V is to 0, the weaker the association is between the two variables.\n",
    "\n",
    "Spearman correlation statistic\n",
    "* To measure the magnitude of an association.\n",
    "\n",
    "odds ratio\n",
    "* To measure the strength of the association between a binary predictor variable and a binary response variable. An odds ratio indicates how much more likely it is that a certain event, or outcome, occurs in one group relative to its occurrence in another group. \n",
    "\n",
    "Mantel-Haenszel chi-square test\n",
    "* The appropriate test to find ordinal associations. For ordinal associations, the Mantel-Haenszel chi-square test is a more powerful test than the Pearson chi-square test. The Mantel-Haenszel test considers only ordinal associations, whereas the Pearson test considers all possible associations.\n",
    "\n",
    "The Spearman Correlation Statistic\n",
    "* To measure the strength of the association between two ordinal variables, you can use the Spearman correlation statistic. The Spearman correlation is a rank correlation, because it provides a degree of association between the ranks, or the levels, of the ordinal variables. This statistic has a range between -1 and 1. Values close to 1 indicate that there’s a relatively high degree of positive correlation. Values close to -1 indicate that there’s a relatively high degree of negative correlation. And values close to 0 indicate a weak correlation. Like other measures of association strength, Spearman's correlation statistic is not affected by sample size.\n",
    "\n",
    "The c, concordance statistic\n",
    "* estimates the probability of an observation with the event having a higher predicted probability than an observation without the event. The c value is calculated as the number of concordant outcomes plus one half times the number of ties divided by the total number of pairs.\n",
    "\n",
    "Optimism principle\n",
    "* The optimism principle states that when you assess the accuracy of a predictive model on the same data that was used to fit the model, you tend to get better assessment statistics than when you assess the model on other data.\n",
    "\n",
    "honest assessment. \n",
    "* To avoid an optimistically biased assessment and create a predictive model that generalizes well, you need to assess the performance of the model on new data that was not used to fit the original model.\n",
    "\n",
    "The Type 3 Analysis of Effects table\n",
    "* shows which input variables are statistically significant, controlling for all of the other input variables in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAS",
   "language": "sas",
   "name": "sas"
  },
  "language_info": {
   "codemirror_mode": "sas",
   "file_extension": ".sas",
   "mimetype": "text/x-sas",
   "name": "sas"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
